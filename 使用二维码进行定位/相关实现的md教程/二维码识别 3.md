

## 一 普通二维摄像头的安装以及测试

### 1 相关驱动的安装

```
sudo apt-get install ros-kinetic-usb-cam
```



### 2 运行摄像头并测试（出现故障就多次插拔USB口重复）

首先运行ros管理器并开启摄像头

```
roscore
roslaunch usb_cam usb_cam-test.launch
```

打开Qt工具箱

```
rqt_image_view
```

在Qt工具箱订阅摄像头/camera/image_raw话题即可。

![](/home/amos/桌面/2019-08-01 17-13-22屏幕截图.png)



### 3 摄像头的标定（出现故障就多次插拔USB口重复）

#### 1）先安装摄像头标定功能包

```
sudo apt-get install ros-kinetic-camera-calibration
```

#### 2）再添加视觉功能包

（ROS配套的，地址为～/ros_exploring/robot_perception/robot_vision，要把它复制到src文件夹，然后再在ros工作空间编译完成，再才能进行下面程序。）

#### 3）启动ros管理器和摄像头

```
roslaunch robot_vision usb_cam.launchroscore
roslaunch robot_vision usb_cam.launch
```

#### 4）启动标定程序（下面代码是一行！！！）

```
rosrun camera_calibration cameracalibrator.py --size 8x6 --square 0.024 image:=/usb_cam/image_raw camera:/usb_cam
```

打开标定程序后，把二维码放在摄像头前反复移动翻转，直到第一个按钮由灰色变成蓝色。然后点击那个按钮，整个界面会卡住几分钟，正常的。卡完了后，直接点击第二个按钮，再点击第三个按钮。（这里留意标定文件的存放位置！！）到此为止，标定结束。



![1564652709265](/home/amos/.config/Typora/typora-user-images/1564652709265.png)

#### 5）把标定文件应用到功能包

在第4）步骤完成后，标定文件就已经生成，找到它后，解压缩，其中ost.yaml文件即为此次的标定结果文件。把它复制到～catkin_ws /src/robot_vision文件夹，然后，重命名为camera_calibration.yaml，替换掉同名文件即可！这样，标定的数据已经可以使用了！下面只需要再次编译一遍ros即可！（编译很简单，在catkin_ws 文件夹下，打开终端，输入catkin_make编译完成即可。）





## 二 二维码识别的实现

### 1 安装ar_track_alvar功能包（出现故障就多次插拔USB口重复）

```
sudo apt-get install ros-kinetic-ar-track-alvar
```



### 2 开始识别二维码

（下面第二行代码运行仍然会报错，多次插拔USB口重复代码即可）

```
roscore
roslaunch robot_vision usb_cam_with_calibration.launch
roslaunch robot_vision ar_track_camera.launch
```



### 3 数据记录与回放

#### 1）数据记录

```
cd ~/bagfiles
rosbag record -a
```

开始记录数据，这时候会有意个端口一直弹警告信息，忽略即可，后面所有的操作已经开始记录。记录完毕后，打开rosbag终端，按下ctrl+c即可停止记录。

#### 2）数据记录回放

打开根目录下的bagfiles文件夹，找到刚刚记录的后缀为.bag的文件,输入下面代码可以查看之前生成的数据记录文件：

```
rosbag info '保存的文件名称.bag'
```

输入下面代码：
(一定注意，之前录入数据时的环境要全部打开，功能包要全部启动完毕，数据才可以复现！)

```
rosbag play '保存的文件名称.bag'
```

就可以看到之前操作过程中，坐标的运动过程。



## 三 将二维码的TF数据发布出去(主要是接收，发布是自动发布的)

### 1 前期知识

TF能发布的数据类型

|              **Type** | **tf**           |
| --------------------: | ---------------- |
| Quaternion （四元数） | `tf::Quaternion` |
|                Vector | `tf::Vector3`    |
|                 Point | `tf::Point`      |
|                  Pose | `tf::Pose`       |
|             Transform | `tf::Transform`  |



查看功能包的依赖功能包：

```
rospack depends robot_vision
```



查看当前二维码跟踪功能包的话题：

```
rostopic list
```



打印某一个话题的数据：

```
rostopic echo 要打印的话题名称
```



使用ar-track-alvar功能包，那么话题ar_pose_marker发布的就是各个二维码的位姿信息，使用如下代码即可查看发布的实时位姿信息：

```
rostopic echo ar_pose_marker
```



### 2 ar_track_alvar功能包介绍

 1）产生不同尺寸/分辨率/包含不同信息的AR标签二维码。

 2）可以识别并跟踪二维码/标签的位姿信息，同时可以集成融合深度相机的深度数据，提升位姿估计精度。

3）同时识别跟踪多个二维码/标签的位姿，好处是，可以更稳定的估计位姿，提升面对图像阻塞时的鲁棒性，并且可以跟踪多边形物体。

4）使用相机图像自动计算捆绑中标签之间的空间关系，以便用户无需手动测量并在XML文件中输入标签位置即可使用捆绑功能。



### 3 ar_track_alvar功能包发布的话题和坐标转换

1）visualization_marker话题

用于在rviz中，addmarker后，选择visualization_marker，可以查看各个二维码的位姿。

2）ar_pose_marker话题

订阅它，可以实时输出各个二维码的位姿信息：

```
rostopic echo ar_pose_marker
```

3）查看坐标转换关系

```
rosrun tf tf_echo [reference_frame] [target_frame]
```

一个例子，查看二维码







